"""
GitHub Good First Issue Timeline Plotter
========================================

Retrieves all GitHub issues with specific labels (e.g., "good first issue",
"good first issue candidate") for a repository or an organization and generates:

â€¢ Per-repo multilabel cumulative timeline PNGs  
â€¢ Organization-wide multilabel summary bar charts (PNG)

Run:
    uv run analytics/good_first_issues.py
"""

from __future__ import annotations
import os
import time
import pathlib
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any

import requests
import pandas as pd
import matplotlib.pyplot as plt
from dotenv import load_dotenv

load_dotenv()

# -----------------------------
# SETTINGS
# -----------------------------
MODE = "org"                                    # "org" or "repo"
ORG = "hiero-ledger"                            # org name if MODE = "org"
REPO = "hiero-ledger/hiero-sdk-python"          # repo name if MODE = "repo"

LABELS = ["good first issue", "good first issue candidate"]
FILTER = "12m"                                   # Timeframe: "all" or "12m"

LABEL_COLORS = {
    "good first issue": "#1f77b4",               # blue
    "good first issue candidate": "#ff7f0e",     # orange
}

TOKEN = os.getenv("GITHUB_TOKEN")
HEADERS = {"Authorization": f"token {TOKEN}"} if TOKEN else {}
REQUEST_DELAY = 0.25

PLOTS_DIR = pathlib.Path("analytics/plots/good_first_issues") # Output location
PLOTS_DIR.mkdir(parents=True, exist_ok=True)

print("ðŸ” Using authenticated GitHub API" if TOKEN else "âš ï¸ No GITHUB_TOKEN found â€” 60 req/hr limit")

# -----------------------------
# GITHUB API HELPERS
# -----------------------------
def safe_get(url: str) -> Any:
    """Perform GitHub GET request with basic rate limit handling."""
    response = requests.get(url, headers=HEADERS)
    remaining = int(response.headers.get("X-RateLimit-Remaining", "1"))
    reset_ts = int(response.headers.get("X-RateLimit-Reset", "0"))

    if remaining <= 0:
        wait = max(0, reset_ts - int(time.time()))
        print(f"â³ Rate limit reached â€” waiting {wait} secondsâ€¦")
        time.sleep(wait)
        response = requests.get(url, headers=HEADERS)

    time.sleep(REQUEST_DELAY)
    return response.json()


def fetch_repos(org: str) -> List[str]:
    """Fetch all repository full names for a given organization."""
    repos = []
    page = 1
    while True:
        url = f"https://api.github.com/orgs/{org}/repos?per_page=100&page={page}"
        data = safe_get(url)
        if not isinstance(data, list) or not data:
            break
        repos.extend(r["full_name"] for r in data)
        if len(data) < 100:
            break
        page += 1
    return repos


def fetch_issues_for_label(repo: str, label: str) -> List[Dict[str, Any]]:
    """Fetch all issues for a given repository with a specific label."""
    issues = []
    page = 1
    while True:
        url = (
            f"https://api.github.com/repos/{repo}/issues"
            f"?state=all&labels={label}&per_page=100&page={page}"
        )
        data = safe_get(url)
        if not isinstance(data, list):
            break
        issues.extend(i for i in data if isinstance(i, dict))
        if len(data) < 100:
            break
        page += 1
    return issues

# -----------------------------
# DATA HELPERS
# -----------------------------
def extract_timestamps(issues: List[Dict[str, Any]]) -> List[pd.Timestamp]:
    """Extract and convert issue creation timestamps to UTC-aware pd.Timestamp objects."""
    ts_raw = [
        issue["created_at"]
        for issue in issues
        if isinstance(issue.get("created_at"), str)
    ]

    # Convert to UTC-aware timestamps
    timestamps = []
    for ts in ts_raw:
        dt = pd.to_datetime(ts)
        timestamps.append(
            dt.tz_convert("UTC") if dt.tzinfo else dt.tz_localize("UTC")
        )
    return timestamps


def filter_dates(dates: List[pd.Timestamp], mode: str) -> List[pd.Timestamp]:
    """Filter dates based on the specified mode."""
    now = datetime.now(timezone.utc)
    if mode == "all":
        return dates
    cutoff = now - timedelta(days=365)
    return [d for d in dates if d >= cutoff]


def build_cumulative_df(dates: List[pd.Timestamp]) -> pd.DataFrame:
    """Build a cumulative count DataFrame from a list of timestamps."""
    df = pd.DataFrame({"created_at": dates})
    df.sort_values("created_at", inplace=True)
    df["count"] = range(1, len(df) + 1)
    return df


def summarize_repo_multilabel(repo: str, issues_by_label: Dict[str, List[Dict[str, Any]]]) -> dict:
    """Generate a summary dictionary for a repository across multiple labels."""
    summary = {"repo": repo}
    now = datetime.now(timezone.utc)

    for label, issues in issues_by_label.items():
        ts = extract_timestamps(issues)

        summary[f"{label}_total"] = len(ts)
        summary[f"{label}_12m"] = sum(d >= now - timedelta(days=365) for d in ts)
        summary[f"{label}_3m"] = sum(d >= now - timedelta(days=90) for d in ts)

        summary[f"{label}_first"] = min(ts).date().isoformat() if ts else None
        summary[f"{label}_last"] = max(ts).date().isoformat() if ts else None

    return summary

# -----------------------------
# SINGLE MULTILABEL PLOT FUNCTION (canonical)
# -----------------------------
def plot_multilabel_timeseries(series: dict, repo: str):
    """Plot cumulative time series for multiple labels on the same chart."""
    repo_safe = repo.replace("/", "_")
    filename = f"{repo_safe}_gfi_multilabel_{FILTER}.png"
    path = PLOTS_DIR / filename

    now = datetime.now(timezone.utc)

    # Determine x-axis window
    if FILTER == "all":
        x_min = min(df["created_at"].min() for df in series.values())
        x_max = max(df["created_at"].max() for df in series.values())
    else:  # "12m"
        x_min = now - timedelta(days=365)
        x_max = now

    plt.figure(figsize=(10, 5))

    for label, df in series.items():
        plt.plot(
            df["created_at"],
            df["count"],
            label=label,
            color=LABEL_COLORS[label],
            marker="o",
            markersize=3,
        )

    plt.xlim(x_min, x_max)
    plt.title(f"Good First Issue Labels Over Time ({FILTER}) â€¢ {repo}")
    plt.xlabel("Date")
    plt.ylabel("Cumulative Count")
    plt.grid(True, alpha=0.4)
    plt.legend()
    plt.tight_layout()
    plt.savefig(path, dpi=300)
    plt.close()

    print(f"   âœ” Saved plot â†’ {path}")

# -----------------------------
# SUMMARY BAR CHARTS
# -----------------------------
def plot_summary_png_multilabel(summary_df: pd.DataFrame, metric_suffix: str, title: str):
    """Plot summary bar chart for multiple labels."""
    label_cols = [f"{label}_{metric_suffix}" for label in LABELS]
    df_sorted = summary_df.sort_values(label_cols[0], ascending=False)
    repos = df_sorted["repo"]

    plt.figure(figsize=(16, 12))

    bar_height = 0.35
    y = range(len(repos))

    for i, label in enumerate(LABELS):
        plt.barh(
            [yy + i * bar_height for yy in y],
            df_sorted[f"{label}_{metric_suffix}"],
            height=bar_height,
            label=label,
            color=LABEL_COLORS[label],
        )

    plt.xlabel("Count")
    plt.title(title)
    plt.yticks([yy + bar_height / 2 for yy in y], repos)
    plt.grid(axis="x", linestyle="--", alpha=0.6)
    plt.legend()
    plt.tight_layout()

    out = PLOTS_DIR / f"summary_multilabel_{metric_suffix}.png"
    plt.savefig(out, dpi=300)
    plt.close()

    print(f"ðŸ“Š Saved â†’ {out}")

# -----------------------------
# REPO WORKFLOW
# -----------------------------
def analyze_repo(repo: str) -> dict:
    """Analyze a single repository for multiple good first issue labels."""
    print(f"\nðŸ“Š Processing {repo}...")

    # Get issues per label
    issues_by_label = {label: fetch_issues_for_label(repo, label) for label in LABELS}

    # Summary table row
    summary = summarize_repo_multilabel(repo, issues_by_label)

    # Build cumulative curves
    series = {}
    for label, issues in issues_by_label.items():
        ts = extract_timestamps(issues)
        ts_f = filter_dates(ts, FILTER)
        if ts_f:
            series[label] = build_cumulative_df(ts_f)

    if series:
        plot_multilabel_timeseries(series, repo)
    else:
        print(f"   â†’ No issues found in the {FILTER} window.")

    return summary

# -----------------------------
# MAIN
# -----------------------------
def main():
    """Main execution function."""
    if MODE == "repo":
        summaries = [analyze_repo(REPO)]
    else:
        repos = fetch_repos(ORG)
        summaries = [analyze_repo(r) for r in repos]

    df = pd.DataFrame(summaries)

    plot_summary_png_multilabel(df, "12m", "Good First Issue Labels â€” Last 12 Months")
    plot_summary_png_multilabel(df, "3m",  "Good First Issue Labels â€” Last 3 Months")
    plot_summary_png_multilabel(df, "total", "Total Good First Issue Labels")


if __name__ == "__main__":
    main()
